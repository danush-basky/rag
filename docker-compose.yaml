services:
  rag-service:
    container_name: rag_service
    build: . 
    
    ports:
      # Maps host port 4545 to container port 4545
      - "4545:4545"
    network_mode: "host"
    volumes:
      - ./:/app
    
    environment:
      # Elasticsearch
      ELASTICSEARCH_HOST: localhost
      ELASTICSEARCH_PORT: 9200
      ELASTICSEARCH_INDEX: documents
      
      # Gemini via OpenAI
      LLM_PROVIDER_URL: https://generativelanguage.googleapis.com/v1beta/openai/
      LLM_API_KEY: ${LLM_API_KEY}
      LLM_MODEL: gemini-2.5-flash
      EMBEDDING_MODEL: models/gemini-embedding-001
      EMBEDDING_DIMS: 768

      # Query Rewriting
      ENABLE_QUERY_REWRITING: true
      QUERY_REWRITE_MODEL: gemini-2.5-flash-lite
      QUERY_REWRITE_MAX_TOKENS: 512
      QUERY_REWRITE_TIMEOUT: 5.0
      QUERY_REWRITE_WITH_HISTORY_COUNT: 5

      # Reranker
      RERANKER_MODEL: cross-encoder/ms-marco-MiniLM-L2-v2
      
      # RAG settings
      TOP_K_RETRIEVAL: 15
      TOP_K_RERANK: 5
      HYBRID_ALPHA: 0.5
      
      # API settings
      MAX_TOKENS: 4096
      TEMPERATURE: 0.7

      LANGFUSE_PUBLIC_KEY: test
      LANGFUSE_SECRET_KEY: test
      LANGFUSE_HOST: http://localhost:3000
      LANGFUSE_DEBUG: false

      DB_HOST: ${RAG_DB_HOST}
      DB_PORT: 5432
      DB_NAME: ${RAG_DB_NAME}
      DB_USER: ${RAG_DB_USERNAME}
      DB_PASSWORD: ${RAG_DB_PASSWORD}
      SUMMARY_TABLE: chat_session_summaries
      HISTORY_TABLE: chat_messages_history
      DB_MIN_CONNECTIONS: 2
      DB_MAX_CONNECTIONS: 5

      MAX_HISTORY_MESSAGES: 10
      SUMMARY_INTERVAL: 5  
      SUMMARY_MODEL: gemini-2.5-flash-lite
      SUMMARY_MAX_TOKENS: 512

      RAG_PORT: 4545
      RAG_GUNICORN_WORKERS: 1
    
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
      
    # networks:
    #   - shared_app_network 
    dns:
      - 8.8.8.8
      - 8.8.4.4